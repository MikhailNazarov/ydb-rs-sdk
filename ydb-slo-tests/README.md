# SLO workload

SLO is the type of test where app based on ydb-sdk is tested against falling YDB cluster nodes, tablets, network
(that is possible situations for distributed DBs with hundreds of nodes)

### Usage:

It has 3 commands:

- `create`  - creates table in database
- `cleanup` - drops table in database
- `run`     - runs workload (read and write to table with sets RPS)

### Run examples with all arguments:

create:

`cargo run --example native grpc://localhost:2136 /local tableName create --min-partitions-count 6 --max-partitions-count 1000 --partition-size 1 -c 1000 --write-timeout 10000`

cleanup:

`cargo run --example native grpc://localhost:2136 /local tableName cleanup`

run:

`cargo run --example native grpc://localhost:2136 /local tableName run -c 1000 --read-rps 1000 --read-timeout 10000 --write-rps 100 --write-timeout 10000 --time 600`

## Arguments for commands:

### create

`cargo run --example <example_name> <ENDPOINT> <DB> <TABLE_NAME> create [OPTIONS]`

```
Arguments:
  ENDPOINT                            YDB endpoint to connect to
  DB                                  YDB database to connect to
  TABLE_NAME                          table name to create

Options:
  --min-partitions-count     <u64>    minimum amount of partitions in table
  --max-partitions-count     <u64>    maximum amount of partitions in table
  --partition-size           <u64>    partition size in mb
  
  -c --initial-data-count    <u64>    amount of initially created rows
  
  --write-timeout            <u64>    write timeout milliseconds
```

### cleanup

`cargo run --example <example_name> <ENDPOINT> <DB> <TABLE_NAME> cleanup`

```
Arguments:
  ENDPOINT    YDB endpoint to connect to
  DB          YDB database to connect to
  TABLE_NAME  table name to cleanup
```

### run

`cargo run --example <example_name> <ENDPOINT> <DB> <TABLE_NAME> run`

```
Arguments:
  ENDPOINT                            YDB endpoint to connect to
  DB                                  YDB database to connect to
  TABLE_NAME                          table name to use

Options:
  -c --initial-data-count    <u64>    amount of initially created rows
                         
  --read-rps                 <u64>    read RPS
  --read-timeout             <u64>    read timeout milliseconds
                         
  --write-rps                <u64>    write RPS
  --write-timeout            <u64>    write timeout milliseconds
                         
  --time                     <u64>    run time in seconds
```

## What's inside

When running `run` command, the program creates two jobs: `readJob`, `writeJob`.

- `readJob`  reads rows from the table one by one with random identifiers generated by `writeJob`
- `writeJob` generates and inserts rows

Table have these fields:

- `hash Uint64`
- `id Uint64`
- `payload_str Text?`
- `payload_double Double?`
- `payload_timestamp Timestamp?`
- `payload_hash Uint64?`

Primary key: `("hash", "id")`
